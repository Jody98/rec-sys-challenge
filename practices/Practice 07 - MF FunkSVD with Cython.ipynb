{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2021/22\n",
    "\n",
    "### Practice - FunkSVD and SVD++ implemented with Python and Cython\n",
    "\n",
    "FunkSVD is one of the simplest and most known matrix factorization models for rating prediction. It was proposed by Simon Funk in a now famous post on his website (with a cow grazing around Auckland): https://sifter.org/~simon/journal/20061211.html\n",
    "\n",
    "SVD++ is an extension of FunkSVD that learns also the biases: global, user and item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T15:58:55.473094Z",
     "start_time": "2023-11-08T15:58:49.825822Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:01:16.860048Z",
     "start_time": "2023-11-08T15:58:58.146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens10M: Preloaded data not found, reading from original files...\n",
      "Movielens10M: Loading original data\n",
      "Movielens10M: Unable to find data zip file. Downloading...\n",
      "Downloading: https://files.grouplens.org/datasets/movielens/ml-10m.zip\n",
      "In folder: /Users/jodyrobertobattistini/PycharmProjects/rec-sys-challenge/Data_manager/../Data_manager_split_datasets/Movielens10M/ml-10m.zip\n",
      "DataReader: Downloaded 38.13%, 23.84 MB, 5466 KB/s, 4 seconds passed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataReader: Downloaded 100.00%, 62.53 MB, 6670 KB/s, 10 seconds passed\n",
      "Movielens10M: Loading Item Features Genres\n",
      "Movielens10M: Loading Item Features Tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jodyrobertobattistini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens10M: Loading Interactions\n",
      "Movielens10M: Cleaning Temporary Files\n",
      "Movielens10M: Loading Complete\n",
      "Movielens10M: Verifying data consistency...\n",
      "Movielens10M: Verifying data consistency... Passed!\n",
      "Movielens10M: Creating folder '/Users/jodyrobertobattistini/PycharmProjects/rec-sys-challenge/Data_manager/../Data_manager_split_datasets/Movielens10M/original/'\n",
      "Movielens10M: Saving complete!\n",
      "DataReader: current dataset is: Movielens10M\n",
      "\tNumber of items: 10681\n",
      "\tNumber of users: 69878\n",
      "\tNumber of interactions in URM_all: 10000054\n",
      "\tValue range in URM_all: 0.50-5.00\n",
      "\tInteraction density: 1.34E-02\n",
      "\tInteractions per user:\n",
      "\t\t Min: 2.00E+01\n",
      "\t\t Avg: 1.43E+02\n",
      "\t\t Max: 7.36E+03\n",
      "\tInteractions per item:\n",
      "\t\t Min: 0.00E+00\n",
      "\t\t Avg: 9.36E+02\n",
      "\t\t Max: 3.49E+04\n",
      "\tGini Index: 0.57\n",
      "\n",
      "\tICM name: ICM_genres, Value range: 1.00 / 1.00, Num features: 20, feature occurrences: 21564, density 1.01E-01\n",
      "\tICM name: ICM_year, Value range: 1.92E+03 / 2.01E+03, Num features: 1, feature occurrences: 10681, density 1.00E+00\n",
      "\tICM name: ICM_tags, Value range: 1.00 / 69.00, Num features: 10106, feature occurrences: 106820, density 9.90E-04\n",
      "\tICM name: ICM_all, Value range: 1.00 / 69.00, Num features: 10126, feature occurrences: 128384, density 1.19E-03\n",
      "\n",
      "Warning: 84 (0.12 %) of 69878 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Data_manager.Movielens.Movielens10MReader import Movielens10MReader\n",
    "\n",
    "data_reader = Movielens10MReader()\n",
    "data_loaded = data_reader.load_data()\n",
    "\n",
    "URM_all = data_loaded.get_URM_all()\n",
    "\n",
    "URM_train, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:01:17.028808Z",
     "start_time": "2023-11-08T16:01:16.956217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<69878x10681 sparse matrix of type '<class 'numpy.float64'>'\n\twith 8000043 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we need for FunkSVD and SVD++?\n",
    "\n",
    "* Loss function\n",
    "* User factor and Item factor matrices\n",
    "* Computing prediction\n",
    "* Update rule\n",
    "* Training loop and some patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:01:34.862131Z",
     "start_time": "2023-11-08T16:01:34.805465Z"
    }
   },
   "outputs": [],
   "source": [
    "n_users, n_items = URM_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The two methods are based on two latent factor matrices $ W \\in R^{U \\times E} , V \\in R^{E \\times I}$ with E the embedding size, and biases $ \\mu \\in R , b_u \\in R^{U}, b_i \\in R^{I}$\n",
    "\n",
    "#### How to compute the predictions\n",
    "FunkSVD: $ \\hat{r}_{ui} = \\sum_{j=0}^{E} W_{uj}H_{ji}$\n",
    "\n",
    "SVD++: $ \\hat{r}_{ui} = \\mu + b_u + b_i + \\sum_{j=0}^{E} W_{uj}H_{ji}$\n",
    "\n",
    "\n",
    "#### The loss function we are interested in minimizing are\n",
    "\n",
    "$L_{FunkSVD} = |R - WH|_F + \\alpha|W|_2 + \\beta|H|_2$\n",
    "\n",
    "$L_{SVD++} = |R - (\\mu + b_u + b_i + WH)|_F + \\alpha|W|_2 + \\beta|H|_2 + \\gamma (\\mu + b_u + b_i) $\n",
    "\n",
    "Notice that in this case the loss is the Frobenius norm, not the 2 norm, hence we want to minimize the prediction error only for the existing ratings not the missing ones. In practice this means one samples only among the observed interactions.\n",
    "\n",
    "While this approach works well for rating prediction, it does not for ranking. A model must be trained also on negative data if it expected to learn how to distinguish between positive and negative data. A good strategy is to randomly sample unobserved interactions during training assigning them a rating of 0.\n",
    "\n",
    "#### Gradients\n",
    "\n",
    "$\\frac{\\partial}{\\partial W} L = -2(R - WH)H + 2\\alpha W $\n",
    "\n",
    "$\\frac{\\partial}{\\partial H} L = -2(R - WH)W + 2\\alpha H $\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\mu} L = -2(R - WH) + 2\\gamma \\mu $\n",
    "\n",
    "$\\frac{\\partial}{\\partial b_u} L = -2(R - WH) + 2\\gamma b_u $\n",
    "\n",
    "$\\frac{\\partial}{\\partial b_i} L = -2(R - WH) + 2\\gamma b_i $\n",
    "\n",
    "#### The update is going to be (we can remove the coefficients)\n",
    "$ W = W - \\frac{\\partial}{\\partial W}$, or \n",
    "\n",
    "$ W = W + l((R - WH)H - \\alpha W)$, with $l$ the learning rate\n",
    "\n",
    "... and similarly for the other parameters: $H$, $\\mu$, $b_u$ and $b_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: We create the dense latent factor matrices\n",
    "### In a MF model you have two matrices, one with a row per user and the other with a column per item. The other dimension, columns for the first one and rows for the second one is called latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:11.846551Z",
     "start_time": "2023-11-08T16:06:11.826578Z"
    }
   },
   "outputs": [],
   "source": [
    "num_factors = 10\n",
    "\n",
    "user_factors = np.random.random((n_users, num_factors))\n",
    "item_factors = np.random.random((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:13.163384Z",
     "start_time": "2023-11-08T16:06:13.146121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.93036035, 0.48943224, 0.53050326, ..., 0.45444864, 0.64604848,\n        0.64109699],\n       [0.94607056, 0.17130545, 0.61676869, ..., 0.75983268, 0.16593878,\n        0.3230319 ],\n       [0.07966808, 0.33538479, 0.57221528, ..., 0.0501624 , 0.53412466,\n        0.98922084],\n       ...,\n       [0.69162328, 0.11788105, 0.48736927, ..., 0.89521311, 0.33903374,\n        0.98055191],\n       [0.23003903, 0.90119835, 0.94220865, ..., 0.67852993, 0.49616145,\n        0.65477644],\n       [0.38752484, 0.76558508, 0.81327766, ..., 0.55046864, 0.83754316,\n        0.45137673]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:14.537367Z",
     "start_time": "2023-11-08T16:06:14.351179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.35537   , 0.64104503, 0.96289777, ..., 0.98117713, 0.41805847,\n        0.23664264],\n       [0.01140409, 0.67748615, 0.81098371, ..., 0.19387806, 0.22144021,\n        0.73798123],\n       [0.50135492, 0.60932249, 0.5399192 , ..., 0.06826006, 0.27701262,\n        0.93081436],\n       ...,\n       [0.06123217, 0.29108337, 0.8131086 , ..., 0.41894751, 0.63334378,\n        0.25505772],\n       [0.06020495, 0.14662926, 0.35827009, ..., 0.20423205, 0.09524987,\n        0.02346607],\n       [0.42066259, 0.00311266, 0.20386564, ..., 0.83131245, 0.17120078,\n        0.35281308]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: We sample an interaction and compute the prediction of the current FunkSVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:22.858622Z",
     "start_time": "2023-11-08T16:06:22.784846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2863734"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_train_coo = URM_train.tocoo()\n",
    "\n",
    "sample_index = np.random.randint(URM_train_coo.nnz)\n",
    "sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:24.828435Z",
     "start_time": "2023-11-08T16:06:24.808799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(25050, 1287, 3.0)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = URM_train_coo.row[sample_index]\n",
    "item_id = URM_train_coo.col[sample_index]\n",
    "rating = URM_train_coo.data[sample_index]\n",
    "\n",
    "(user_id, item_id, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:26.584740Z",
     "start_time": "2023-11-08T16:06:26.569907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.098379193671592"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rating = np.dot(user_factors[user_id,:], item_factors[item_id,:])\n",
    "predicted_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first predicted rating is a random prediction, essentially\n",
    "\n",
    "### Step 3: We compute the prediction error and update the latent factor matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:06:37.736655Z",
     "start_time": "2023-11-08T16:06:37.721788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "-1.098379193671592"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_error = rating - predicted_rating\n",
    "prediction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The error is positive, so we need to increase the prediction our model computes. Meaning, we have to increase the values latent factor matrices\n",
    "\n",
    "### Which latent factors we modify? All the factors of the item and user we used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:12.245115Z",
     "start_time": "2023-11-08T16:07:12.219724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy original value to avoid messing up the updates\n",
    "H_i = item_factors[item_id,:]\n",
    "W_u = user_factors[user_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:12.758668Z",
     "start_time": "2023-11-08T16:07:12.741385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.5587849 , 0.05969929, 0.64214014, 0.6822657 , 0.32228913,\n       0.50669907, 0.96267464, 0.91001872, 0.72677112, 0.9647236 ])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:13.905942Z",
     "start_time": "2023-11-08T16:07:13.890109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.12091094, 0.24717702, 0.96734792, 0.9617698 , 0.75169658,\n       0.31167153, 0.39781027, 0.541235  , 0.85755123, 0.87048519])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the update rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:16.050873Z",
     "start_time": "2023-11-08T16:07:16.030729Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "regularization = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:18.770919Z",
     "start_time": "2023-11-08T16:07:18.754454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.61375892, -0.06557493, -0.70532304, -0.74939606, -0.35400319,\n       -0.55655083, -1.05738577, -0.99955104, -0.79827886, -1.05964104])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors_update = prediction_error * H_i - regularization * W_u\n",
    "user_factors_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:20.140717Z",
     "start_time": "2023-11-08T16:07:20.131432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.13281165, -0.27149469, -1.06252125, -1.05639476, -0.8256511 ,\n       -0.34233859, -0.43695615, -0.59449036, -0.94192369, -0.95613247])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors_update = prediction_error * W_u - regularization * H_i\n",
    "item_factors_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:21.228526Z",
     "start_time": "2023-11-08T16:07:21.200077Z"
    }
   },
   "outputs": [],
   "source": [
    "user_factors[user_id,:] += learning_rate * user_factors_update \n",
    "item_factors[item_id,:] += learning_rate * item_factors_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check what the new prediction for the same user-item interaction would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:26.101315Z",
     "start_time": "2023-11-08T16:07:26.082449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.097356533335718"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_rating = np.dot(user_factors[user_id,:], item_factors[item_id,:])\n",
    "predicted_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The value is higher than before, we are moving in the right direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now? Sample another interaction and repeat... a lot of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING: Initialization must be done with random non-zero values ... otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:35.631667Z",
     "start_time": "2023-11-08T16:07:35.613225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 0.00\n",
      "Prediction error is 3.00\n"
     ]
    }
   ],
   "source": [
    "user_factors = np.zeros((n_users, num_factors))\n",
    "item_factors = np.zeros((n_items, num_factors))\n",
    "\n",
    "predicted_rating = np.dot(user_factors[user_id,:], item_factors[item_id,:])\n",
    "\n",
    "print(\"Prediction is {:.2f}\".format(predicted_rating))\n",
    "\n",
    "prediction_error = rating - predicted_rating\n",
    "\n",
    "print(\"Prediction error is {:.2f}\".format(prediction_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:36.430481Z",
     "start_time": "2023-11-08T16:07:36.420151Z"
    }
   },
   "outputs": [],
   "source": [
    "H_i = item_factors[item_id,:]\n",
    "W_u = user_factors[user_id,:]\n",
    "\n",
    "user_factors[user_id,:] += learning_rate * (prediction_error * H_i - regularization * W_u)\n",
    "item_factors[item_id,:] += learning_rate * (prediction_error * W_u - regularization * H_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:07:39.297813Z",
     "start_time": "2023-11-08T16:07:39.261944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction after the update is 0.00\n",
      "Prediction error is 3.00\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = np.dot(user_factors[user_id,:], item_factors[item_id,:])\n",
    "\n",
    "print(\"Prediction after the update is {:.2f}\".format(predicted_rating))\n",
    "print(\"Prediction error is {:.2f}\".format(rating - predicted_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the matrices are multiplied, if we initialize one of them as zero, the updates will always be zero and the model will not be able to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put all together in a training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:08:13.629514Z",
     "start_time": "2023-11-08T16:07:54.213587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100000 in 1.93 seconds, loss is 2.60. Samples per second 51932.59\n",
      "Iteration 200000 in 3.84 seconds, loss is 2.56. Samples per second 52096.79\n",
      "Iteration 300000 in 5.78 seconds, loss is 2.53. Samples per second 51932.04\n",
      "Iteration 400000 in 7.71 seconds, loss is 2.51. Samples per second 51859.77\n",
      "Iteration 500000 in 9.64 seconds, loss is 2.48. Samples per second 51877.02\n",
      "Iteration 600000 in 11.56 seconds, loss is 2.45. Samples per second 51898.52\n",
      "Iteration 700000 in 13.49 seconds, loss is 2.43. Samples per second 51897.02\n",
      "Iteration 800000 in 15.47 seconds, loss is 2.41. Samples per second 51723.54\n",
      "Iteration 900000 in 17.39 seconds, loss is 2.39. Samples per second 51752.04\n",
      "Iteration 1000000 in 19.34 seconds, loss is 2.37. Samples per second 51718.31\n"
     ]
    }
   ],
   "source": [
    "URM_train_coo = URM_train.tocoo()\n",
    "\n",
    "num_factors = 10\n",
    "learning_rate = 1e-4\n",
    "regularization = 1e-5\n",
    "\n",
    "user_factors = np.random.random((n_users, num_factors))\n",
    "item_factors = np.random.random((n_items, num_factors))\n",
    "\n",
    "loss = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for sample_num in range(1000000):\n",
    "    \n",
    "    # Randomly pick sample\n",
    "    sample_index = np.random.randint(URM_train_coo.nnz)\n",
    "\n",
    "    user_id = URM_train_coo.row[sample_index]\n",
    "    item_id = URM_train_coo.col[sample_index]\n",
    "    rating = URM_train_coo.data[sample_index]\n",
    "\n",
    "    # Compute prediction\n",
    "    predicted_rating = np.dot(user_factors[user_id,:], item_factors[item_id,:])\n",
    "        \n",
    "    # Compute prediction error, or gradient\n",
    "    prediction_error = rating - predicted_rating\n",
    "    loss += prediction_error**2\n",
    "    \n",
    "    # Copy original value to avoid messing up the updates\n",
    "    H_i = item_factors[item_id,:]\n",
    "    W_u = user_factors[user_id,:]  \n",
    "    \n",
    "    user_factors_update = prediction_error * H_i - regularization * W_u\n",
    "    item_factors_update = prediction_error * W_u - regularization * H_i\n",
    "    \n",
    "    user_factors[user_id,:] += learning_rate * user_factors_update \n",
    "    item_factors[item_id,:] += learning_rate * item_factors_update    \n",
    "    \n",
    "    # Print some stats\n",
    "    if (sample_num +1)% 100000 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        samples_per_second = sample_num/elapsed_time\n",
    "        print(\"Iteration {} in {:.2f} seconds, loss is {:.2f}. Samples per second {:.2f}\".format(sample_num+1, elapsed_time, loss/sample_num, samples_per_second))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we see? The loss generally goes down but may oscillate a bit.\n",
    "### How long do we train such a model?\n",
    "\n",
    "* An epoch: a complete loop over all the train data\n",
    "* Usually you train for multiple epochs. Depending on the algorithm and data 10s or 100s of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:08:33.103656Z",
     "start_time": "2023-11-08T16:08:33.088005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated time with the previous training speed is 1546.84 seconds, or 25.78 minutes\n"
     ]
    }
   ],
   "source": [
    "estimated_seconds = 8e6 * 10 / samples_per_second\n",
    "print(\"Estimated time with the previous training speed is {:.2f} seconds, or {:.2f} minutes\".format(estimated_seconds, estimated_seconds/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model is relatively quick\n",
    "\n",
    "### Let's see what we can do with Cython\n",
    "### First step, just compile it. We do not have the data at compile time, so we put the loop in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:08:41.335586Z",
     "start_time": "2023-11-08T16:08:39.367059Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:08:47.736054Z",
     "start_time": "2023-11-08T16:08:41.339900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stderr:\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5200:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5211:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5321:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5332:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5510:26: warning: code will never be executed [-Wunreachable-code]\n",
      "                module = PyImport_ImportModuleLevelObject(\n",
      "                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5 warnings generated.\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5200:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5211:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5321:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5332:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:530:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_2d8c9f90376a38eb682a7450b616ee756322867f.c:5510:26: warning: code will never be executed [-Wunreachable-code]\n",
      "                module = PyImport_ImportModuleLevelObject(\n",
      "                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5 warnings generated."
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def do_some_training(URM_train):\n",
    "\n",
    "    URM_train_coo = URM_train.tocoo()\n",
    "    n_users, n_items = URM_train_coo.shape\n",
    "\n",
    "    num_factors = 10\n",
    "    learning_rate = 1e-4\n",
    "    regularization = 1e-5\n",
    "\n",
    "    user_factors = np.random.random((n_users, num_factors))\n",
    "    item_factors = np.random.random((n_items, num_factors))\n",
    "\n",
    "    loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for sample_num in range(1000000):\n",
    "\n",
    "        # Randomly pick sample\n",
    "        sample_index = np.random.randint(URM_train_coo.nnz)\n",
    "\n",
    "        user_id = URM_train_coo.row[sample_index]\n",
    "        item_id = URM_train_coo.col[sample_index]\n",
    "        rating = URM_train_coo.data[sample_index]\n",
    "\n",
    "        # Compute prediction\n",
    "        predicted_rating = np.dot(user_factors[user_id,:], item_factors[item_id,:])\n",
    "\n",
    "        # Compute prediction error, or gradient\n",
    "        prediction_error = rating - predicted_rating\n",
    "        loss += prediction_error**2\n",
    "\n",
    "        # Copy original value to avoid messing up the updates\n",
    "        H_i = item_factors[item_id,:]\n",
    "        W_u = user_factors[user_id,:]  \n",
    "\n",
    "        user_factors_update = prediction_error * H_i - regularization * W_u\n",
    "        item_factors_update = prediction_error * W_u - regularization * H_i\n",
    "\n",
    "        user_factors[user_id,:] += learning_rate * user_factors_update \n",
    "        item_factors[item_id,:] += learning_rate * item_factors_update    \n",
    "\n",
    "        # Print some stats\n",
    "        if (sample_num +1)% 100000 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            samples_per_second = sample_num/elapsed_time\n",
    "            print(\"Iteration {} in {:.2f} seconds, loss is {:.2f}. Samples per second {:.2f}\".format(sample_num+1, elapsed_time, loss/sample_num, samples_per_second))\n",
    "\n",
    "    return loss, samples_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:09:12.267539Z",
     "start_time": "2023-11-08T16:08:54.022433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100000 in 2.24 seconds, loss is 2.62. Samples per second 44639.96\n",
      "Iteration 200000 in 3.97 seconds, loss is 2.61. Samples per second 50333.10\n",
      "Iteration 300000 in 5.76 seconds, loss is 2.58. Samples per second 52099.69\n",
      "Iteration 400000 in 7.55 seconds, loss is 2.55. Samples per second 52995.55\n",
      "Iteration 500000 in 9.32 seconds, loss is 2.52. Samples per second 53640.46\n",
      "Iteration 600000 in 11.13 seconds, loss is 2.49. Samples per second 53893.23\n",
      "Iteration 700000 in 12.90 seconds, loss is 2.47. Samples per second 54280.93\n",
      "Iteration 800000 in 14.63 seconds, loss is 2.45. Samples per second 54686.36\n",
      "Iteration 900000 in 16.39 seconds, loss is 2.43. Samples per second 54912.45\n",
      "Iteration 1000000 in 18.17 seconds, loss is 2.41. Samples per second 55036.91\n"
     ]
    }
   ],
   "source": [
    "loss, samples_per_second = do_some_training(URM_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:09:14.915364Z",
     "start_time": "2023-11-08T16:09:14.898672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated time with the previous training speed is 1453.57 seconds, or 24.23 minutes\n"
     ]
    }
   ],
   "source": [
    "estimated_seconds = 8e6 * 10 / samples_per_second\n",
    "print(\"Estimated time with the previous training speed is {:.2f} seconds, or {:.2f} minutes\".format(estimated_seconds, estimated_seconds/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The compiler is just porting in C all operations that the python interpreter would have to perform, dynamic tiping included. Have a look at the html reports in the Cython_examples folder\n",
    "\n",
    "### Now try to add some types: If you use a variable only as a C object, use primitive tipes\n",
    "\n",
    "* cdef int namevar\n",
    "* cdef double namevar\n",
    "* cdef float namevar\n",
    "* cdef double[:] singledimensionarray\n",
    "* cdef double[:,:] bidimensionalmatrix\n",
    "\n",
    "### Some operations are still done with sparse matrices, those cannot be correctly optimized because the compiler does not know how what is the type of the data.\n",
    "\n",
    "### To address this, we create typed arrays in which we put the URM_train data\n",
    "For example, this operation: user_id = URM_train_coo.row[sample_index]\n",
    "\n",
    "Becomes:\n",
    "cdef int user_id\n",
    "cdef int[:] URM_train_coo_row = URM_train_coo.row\n",
    "user_id = URM_train_coo_row[sample_index]\n",
    "\n",
    "### We can also skip the creation of the items_in_user_profile array and replace the np.random call with the faster native C function rand()\n",
    "\n",
    "\n",
    "### We now use types for all main variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:09:58.772825Z",
     "start_time": "2023-11-08T16:09:50.291496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stderr:\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_4066a0420c9d9b55cfe53e13f942763025db5a1c.c:22933:26: warning: code will never be executed [-Wunreachable-code]\n",
      "                module = PyImport_ImportModuleLevelObject(\n",
      "                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "1 warning generated.\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_4066a0420c9d9b55cfe53e13f942763025db5a1c.c:22933:26: warning: code will never be executed [-Wunreachable-code]\n",
      "                module = PyImport_ImportModuleLevelObject(\n",
      "                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "1 warning generated."
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from libc.stdlib cimport rand, srand, RAND_MAX\n",
    "\n",
    "def do_some_training(URM_train):\n",
    "\n",
    "    URM_train_coo = URM_train.tocoo()\n",
    "    n_users, n_items = URM_train_coo.shape\n",
    "    cdef int n_interactions = URM_train.nnz\n",
    "    \n",
    "    cdef int sample_num, sample_index, user_id, item_id, factor_index\n",
    "    cdef double rating, predicted_rating, prediction_error\n",
    "\n",
    "    cdef int num_factors = 10\n",
    "    cdef double learning_rate = 1e-4\n",
    "    cdef double regularization = 1e-5\n",
    "    \n",
    "    cdef int[:] URM_train_coo_row = URM_train_coo.row\n",
    "    cdef int[:] URM_train_coo_col = URM_train_coo.col\n",
    "    cdef double[:] URM_train_coo_data = URM_train_coo.data\n",
    "    \n",
    "    cdef double[:,:] user_factors = np.random.random((n_users, num_factors))\n",
    "    cdef double[:,:] item_factors = np.random.random((n_items, num_factors))\n",
    "    cdef double H_i, W_u\n",
    "    cdef double item_factors_update, user_factors_update\n",
    "                \n",
    "    cdef double loss = 0.0\n",
    "    cdef long start_time = time.time()\n",
    "\n",
    "    for sample_num in range(URM_train.nnz):\n",
    "\n",
    "        # Randomly pick sample\n",
    "        sample_index = rand() % n_interactions\n",
    "\n",
    "        user_id = URM_train_coo_row[sample_index]\n",
    "        item_id = URM_train_coo_col[sample_index]\n",
    "        rating = URM_train_coo_data[sample_index]\n",
    "\n",
    "        # Compute prediction\n",
    "        predicted_rating = 0.0\n",
    "        \n",
    "        for factor_index in range(num_factors):\n",
    "            predicted_rating += user_factors[user_id, factor_index] * item_factors[item_id, factor_index]\n",
    " \n",
    "        # Compute prediction error, or gradient\n",
    "        prediction_error = rating - predicted_rating\n",
    "        loss += prediction_error**2\n",
    "\n",
    "        # Copy original value to avoid messing up the updates\n",
    "        for factor_index in range(num_factors):\n",
    "            \n",
    "            H_i = item_factors[item_id,factor_index]\n",
    "            W_u = user_factors[user_id,factor_index]  \n",
    "\n",
    "            user_factors_update = prediction_error * H_i - regularization * W_u\n",
    "            item_factors_update = prediction_error * W_u - regularization * H_i\n",
    "\n",
    "            user_factors[user_id,factor_index] += learning_rate * user_factors_update \n",
    "            item_factors[item_id,factor_index] += learning_rate * item_factors_update    \n",
    "\n",
    "        # Print some stats\n",
    "        if (sample_num +1)% 500000 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            samples_per_second = sample_num/elapsed_time\n",
    "            print(\"Iteration {} in {:.2f} seconds, loss is {:.2f}. Samples per second {:.2f}\".format(sample_num+1, elapsed_time, loss/sample_num, samples_per_second))\n",
    "\n",
    "    return loss, samples_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:10:08.072107Z",
     "start_time": "2023-11-08T16:10:05.269411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500000 in 0.50 seconds, loss is 2.44. Samples per second 993948.48\n",
      "Iteration 1000000 in 0.64 seconds, loss is 2.34. Samples per second 1564911.70\n",
      "Iteration 1500000 in 0.93 seconds, loss is 2.25. Samples per second 1619813.66\n",
      "Iteration 2000000 in 1.30 seconds, loss is 2.19. Samples per second 1533497.19\n",
      "Iteration 2500000 in 1.54 seconds, loss is 2.13. Samples per second 1619487.28\n",
      "Iteration 3000000 in 1.69 seconds, loss is 2.08. Samples per second 1776323.58\n",
      "Iteration 3500000 in 1.83 seconds, loss is 2.04. Samples per second 1917155.43\n",
      "Iteration 4000000 in 1.96 seconds, loss is 2.00. Samples per second 2042378.71\n",
      "Iteration 4500000 in 2.10 seconds, loss is 1.97. Samples per second 2147580.30\n",
      "Iteration 5000000 in 2.24 seconds, loss is 1.94. Samples per second 2235765.70\n",
      "Iteration 5500000 in 2.37 seconds, loss is 1.91. Samples per second 2318344.67\n",
      "Iteration 6000000 in 2.51 seconds, loss is 1.88. Samples per second 2392238.22\n",
      "Iteration 6500000 in 2.65 seconds, loss is 1.86. Samples per second 2454662.95\n",
      "Iteration 7000000 in 2.78 seconds, loss is 1.83. Samples per second 2514451.29\n",
      "Iteration 7500000 in 2.92 seconds, loss is 1.81. Samples per second 2571641.32\n",
      "Iteration 8000000 in 3.05 seconds, loss is 1.80. Samples per second 2621973.08\n"
     ]
    }
   ],
   "source": [
    "loss, samples_per_second = do_some_training(URM_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:10:19.231909Z",
     "start_time": "2023-11-08T16:10:19.216222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated time with the previous training speed is 30.51 seconds, or 0.51 minutes\n"
     ]
    }
   ],
   "source": [
    "estimated_seconds = 8e6 * 10 / samples_per_second\n",
    "print(\"Estimated time with the previous training speed is {:.2f} seconds, or {:.2f} minutes\".format(estimated_seconds, estimated_seconds/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Works nicely, let's put an additional for loop to do multiple epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:10:37.573371Z",
     "start_time": "2023-11-08T16:10:29.249662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of stderr:\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:23231:26: warning: code will never be executed [-Wunreachable-code]\n",
      "                module = PyImport_ImportModuleLevelObject(\n",
      "                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:23746:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:533:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:23757:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:533:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "3 warnings generated.\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:23231:26: warning: code will never be executed [-Wunreachable-code]\n",
      "                module = PyImport_ImportModuleLevelObject(\n",
      "                         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:23746:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:533:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:23757:21: warning: fallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "                    ^\n",
      "/Users/jodyrobertobattistini/.ipython/cython/_cython_magic_9a1303b32c8f966755c4784110fb0e619e65e676.c:533:34: note: expanded from macro 'CYTHON_FALLTHROUGH'\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "                                 ^\n",
      "3 warnings generated."
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from libc.stdlib cimport rand, srand, RAND_MAX\n",
    "\n",
    "def train_multiple_epochs(URM_train, learning_rate_input, regularization_input, n_epochs):\n",
    "    \n",
    "    URM_train_coo = URM_train.tocoo()\n",
    "    n_users, n_items = URM_train_coo.shape\n",
    "    cdef int n_interactions = URM_train.nnz\n",
    "    \n",
    "    cdef int sample_num, sample_index, user_id, item_id, factor_index\n",
    "    cdef double rating, predicted_rating, prediction_error\n",
    "\n",
    "    cdef int num_factors = 10\n",
    "    cdef double learning_rate = learning_rate_input\n",
    "    cdef double regularization = regularization_input\n",
    "    \n",
    "    cdef int[:] URM_train_coo_row = URM_train_coo.row\n",
    "    cdef int[:] URM_train_coo_col = URM_train_coo.col\n",
    "    cdef double[:] URM_train_coo_data = URM_train_coo.data\n",
    "\n",
    "    cdef double[:,:] user_factors = np.random.random((n_users, num_factors))\n",
    "    cdef double[:,:] item_factors = np.random.random((n_items, num_factors))\n",
    "    cdef double H_i, W_u\n",
    "    cdef double item_factors_update, user_factors_update\n",
    "                \n",
    "    cdef double loss = 0.0\n",
    "    cdef long start_time = time.time()\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "\n",
    "        loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for sample_num in range(URM_train.nnz):\n",
    "\n",
    "            # Randomly pick sample\n",
    "            sample_index = rand() % n_interactions\n",
    "\n",
    "            user_id = URM_train_coo_row[sample_index]\n",
    "            item_id = URM_train_coo_col[sample_index]\n",
    "            rating = URM_train_coo_data[sample_index]\n",
    "\n",
    "            # Compute prediction\n",
    "            predicted_rating = 0.0\n",
    "\n",
    "            for factor_index in range(num_factors):\n",
    "                predicted_rating += user_factors[user_id, factor_index] * item_factors[item_id, factor_index]\n",
    "\n",
    "            # Compute prediction error, or gradient\n",
    "            prediction_error = rating - predicted_rating\n",
    "            loss += prediction_error**2\n",
    "\n",
    "            # Copy original value to avoid messing up the updates\n",
    "            for factor_index in range(num_factors):\n",
    "\n",
    "                H_i = item_factors[item_id,factor_index]\n",
    "                W_u = user_factors[user_id,factor_index]  \n",
    "\n",
    "                user_factors_update = prediction_error * H_i - regularization * W_u\n",
    "                item_factors_update = prediction_error * W_u - regularization * H_i\n",
    "\n",
    "                user_factors[user_id,factor_index] += learning_rate * user_factors_update \n",
    "                item_factors[item_id,factor_index] += learning_rate * item_factors_update    \n",
    "            \n",
    "        elapsed_time = time.time() - start_time\n",
    "        samples_per_second = sample_num/elapsed_time\n",
    "     \n",
    "        print(\"Epoch {} complete in in {:.2f} seconds, loss is {:.3E}. Samples per second {:.2f}\".format(n_epoch+1, time.time() - start_time, loss/sample_num, samples_per_second))\n",
    "\n",
    "    return np.array(user_factors), np.array(item_factors), loss, samples_per_second    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T16:11:02.232597Z",
     "start_time": "2023-11-08T16:10:39.976665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete in in 2.54 seconds, loss is 1.172E+00. Samples per second 3154364.41\n",
      "Epoch 2 complete in in 2.67 seconds, loss is 8.915E-01. Samples per second 2994942.51\n",
      "Epoch 3 complete in in 2.82 seconds, loss is 8.307E-01. Samples per second 2841360.89\n",
      "Epoch 4 complete in in 3.37 seconds, loss is 8.009E-01. Samples per second 2376559.85\n",
      "Epoch 5 complete in in 2.49 seconds, loss is 7.839E-01. Samples per second 3213890.54\n",
      "Epoch 6 complete in in 2.63 seconds, loss is 7.731E-01. Samples per second 3042099.06\n",
      "Epoch 7 complete in in 2.77 seconds, loss is 7.654E-01. Samples per second 2887246.95\n",
      "Epoch 8 complete in in 2.91 seconds, loss is 7.599E-01. Samples per second 2753362.18\n",
      "Epoch 9 complete in in 3.04 seconds, loss is 7.562E-01. Samples per second 2627521.08\n",
      "Epoch 10 complete in in 2.18 seconds, loss is 7.528E-01. Samples per second 3661654.60\n"
     ]
    }
   ],
   "source": [
    "n_items = URM_train.shape[1]\n",
    "learning_rate = 1e-3\n",
    "regularization = 1e-5\n",
    "    \n",
    "user_factors, item_factors, loss, samples_per_second =  train_multiple_epochs(URM_train, learning_rate, regularization, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 20 minutes of training time to a few seconds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
